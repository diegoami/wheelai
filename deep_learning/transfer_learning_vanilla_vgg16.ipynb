{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = \"/media/shreyas/DATA/ML_DATA/traffic_signs/train.p\"\n",
    "valid_data = \"/media/shreyas/DATA/ML_DATA/traffic_signs/valid.p\"\n",
    "test_data = \"/media/shreyas/DATA/ML_DATA/traffic_signs/test.p\"\n",
    "results = \"/media/shreyas/DATA/ML_DATA/traffic_signs/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.backend import tf as k\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from utils import *\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "with open(train_data, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(test_data, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open(valid_data, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/cAAAF0CAYAAABmPcmQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5022f60828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_label_counter = Counter(y_train)\n",
    "\n",
    "train_counter = Counter(y_train)\n",
    "order = list(zip(*train_counter.most_common()))[0]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 4))\n",
    "ax = sns.countplot(x=y_train, order=order, color='lightblue', ax=ax, label=\"train\")\n",
    "\n",
    "_ = ax.set_title('Class distribution')\n",
    "_ = ax.legend(ncol=2, loc=\"upper right\", frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (34799, 32, 32, 3)\n",
      "34799 train samples\n",
      "4410 valid samples\n",
      "12630 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'valid samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_samples = X_train.shape[0]\n",
    "nb_valid_samples = X_valid.shape[0]\n",
    "batch_size = 32\n",
    "steps_per_epoch = nb_train_samples // batch_size\n",
    "valid_steps = nb_valid_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 43)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 43)\n",
    "Y_valid = np_utils.to_categorical(y_valid, 43)\n",
    "Y_test = np_utils.to_categorical(y_test, 43)\n",
    "\n",
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_resize(X, h, w):\n",
    "    inp = Input(shape=(None, None, 3))\n",
    "    out = Lambda(lambda image: k.image.resize_images(image, (h, w)))(inp)\n",
    "\n",
    "    model = Model(input=inp, output=out)\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"la..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "X_trn299 = image_resize(X_train, 299, 299)\n",
    "X_vld299 = image_resize(X_valid, 299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(results + 'X_trn299.dat', X_trn299)\n",
    "save_array(results + 'X_vld299.dat', X_vld299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn299 = load_array(results + 'X_trn299.dat')\n",
    "X_vld299 = load_array(results + 'X_vld299.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 299, 299, 3) (4410, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print (X_trn299.shape, X_vld299.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ft = vgg.predict(X_trn224)\n",
    "vld_ft = vgg.predict(X_vld224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trn_ft.shape, vld_ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(results + 'trn_vgg.dat', trn_ft)\n",
    "save_array(results + 'val_vgg.dat', vld_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "res50 = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res50.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_ft = res50.predict(X_trn224)\n",
    "vld_ft = res50.predict(X_vld224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(results + 'trn_res.dat', trn_ft)\n",
    "save_array(results + 'val_res.dat', vld_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 1, 1, 2048) (4410, 1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(trn_ft.shape, vld_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "xception = Xception(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "xception.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ft = xception.predict(X_trn299)\n",
    "vld_ft = xception.predict(X_vld299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(results + 'trn_xception.dat', trn_ft)\n",
    "save_array(results + 'val_xception.dat', vld_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(trn_ft.shape, vld_ft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trn = load_array(results + 'trn_vgg.dat')\n",
    "X_vld = load_array(results + 'val_vgg.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 7, 7, 512) (4410, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "print(X_trn.shape, X_vld.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(X_trn.shape[1:]))\n",
    "x = Flatten()(inp)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "ouput_layer = Dense(43, activation='softmax')(x)\n",
    "model = Model(inputs=inp, outputs=ouput_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/3\n",
      "34799/34799 [==============================] - 6s - loss: 0.8421 - acc: 0.7719 - val_loss: 1.3683 - val_acc: 0.6435\n",
      "Epoch 2/3\n",
      "34799/34799 [==============================] - 4s - loss: 0.3034 - acc: 0.9071 - val_loss: 1.7592 - val_acc: 0.6274\n",
      "Epoch 3/3\n",
      "34799/34799 [==============================] - 4s - loss: 0.2472 - acc: 0.9237 - val_loss: 1.6421 - val_acc: 0.6755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51812fcf60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=3, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.2065 - acc: 0.9349 - val_loss: 1.8986 - val_acc: 0.6857\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1886 - acc: 0.9430 - val_loss: 1.7470 - val_acc: 0.6902\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1755 - acc: 0.9458 - val_loss: 1.7338 - val_acc: 0.7136\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1719 - acc: 0.9493 - val_loss: 1.9411 - val_acc: 0.6880\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1540 - acc: 0.9532 - val_loss: 2.1819 - val_acc: 0.6902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5181d7b470>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1564 - acc: 0.9532 - val_loss: 1.8765 - val_acc: 0.7270\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1453 - acc: 0.9566 - val_loss: 2.0802 - val_acc: 0.7136\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1334 - acc: 0.9599 - val_loss: 2.3624 - val_acc: 0.6961\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1469 - acc: 0.9595 - val_loss: 2.4665 - val_acc: 0.7116\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1375 - acc: 0.9602 - val_loss: 2.2115 - val_acc: 0.7172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5181d2ea90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1369 - acc: 0.9610 - val_loss: 2.4147 - val_acc: 0.7120\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1309 - acc: 0.9619 - val_loss: 2.2834 - val_acc: 0.7193\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1222 - acc: 0.9659 - val_loss: 2.5302 - val_acc: 0.7197\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1192 - acc: 0.9656 - val_loss: 2.3415 - val_acc: 0.7181\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1206 - acc: 0.9664 - val_loss: 2.3875 - val_acc: 0.7299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5181d7b320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1158 - acc: 0.9663 - val_loss: 2.5337 - val_acc: 0.7029\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1161 - acc: 0.9681 - val_loss: 2.5439 - val_acc: 0.7181\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1126 - acc: 0.9686 - val_loss: 2.5697 - val_acc: 0.7154\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1214 - acc: 0.9681 - val_loss: 2.7023 - val_acc: 0.7213\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 4s - loss: 0.1034 - acc: 0.9706 - val_loss: 2.6350 - val_acc: 0.7193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f518127ed68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(X_trn.shape[1:]))\n",
    "x = Flatten()(inp)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='elu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='elu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.8)(x)\n",
    "ouput_layer = Dense(43, activation='softmax')(x)\n",
    "model = Model(inputs=inp, outputs=ouput_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/3\n",
      "34799/34799 [==============================] - 5s - loss: 7.0149 - acc: 0.3919 - val_loss: 4.7352 - val_acc: 0.4882\n",
      "Epoch 2/3\n",
      "34799/34799 [==============================] - 5s - loss: 3.7009 - acc: 0.6104 - val_loss: 3.3275 - val_acc: 0.6304\n",
      "Epoch 3/3\n",
      "34799/34799 [==============================] - 5s - loss: 3.0076 - acc: 0.6649 - val_loss: 2.8912 - val_acc: 0.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50601c6908>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=3, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.7675 - acc: 0.6842 - val_loss: 2.8245 - val_acc: 0.6594\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.6732 - acc: 0.6934 - val_loss: 2.7684 - val_acc: 0.6730\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.6245 - acc: 0.7026 - val_loss: 2.7480 - val_acc: 0.6512\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.5896 - acc: 0.7113 - val_loss: 2.7650 - val_acc: 0.6744\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.5403 - acc: 0.7208 - val_loss: 2.6649 - val_acc: 0.6626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51812a20f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.5199 - acc: 0.7257 - val_loss: 2.6433 - val_acc: 0.6828\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.4718 - acc: 0.7364 - val_loss: 2.6386 - val_acc: 0.6868\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.4640 - acc: 0.7407 - val_loss: 2.5006 - val_acc: 0.7043\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.4625 - acc: 0.7413 - val_loss: 2.6867 - val_acc: 0.6884\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.4257 - acc: 0.7534 - val_loss: 2.6195 - val_acc: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5060097dd8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.4099 - acc: 0.7590 - val_loss: 2.6108 - val_acc: 0.6950\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.3469 - acc: 0.7673 - val_loss: 2.6158 - val_acc: 0.7048\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.3802 - acc: 0.7667 - val_loss: 2.4896 - val_acc: 0.7200\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.3390 - acc: 0.7714 - val_loss: 2.4851 - val_acc: 0.7234\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.3320 - acc: 0.7742 - val_loss: 2.4670 - val_acc: 0.7261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f517fb938d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.2901 - acc: 0.7808 - val_loss: 2.4400 - val_acc: 0.7163\n",
      "Epoch 2/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.2807 - acc: 0.7802 - val_loss: 2.3538 - val_acc: 0.7329\n",
      "Epoch 3/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.2128 - acc: 0.7833 - val_loss: 2.3306 - val_acc: 0.7134\n",
      "Epoch 4/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.2413 - acc: 0.7848 - val_loss: 2.4555 - val_acc: 0.7261\n",
      "Epoch 5/5\n",
      "34799/34799 [==============================] - 5s - loss: 2.1991 - acc: 0.7901 - val_loss: 2.2570 - val_acc: 0.7678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50600a5160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=5, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "vgg.summary()\n",
    "#for layer in vgg.layers[:15]: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "layers = vgg.layers\n",
    "maxpool_idx = [index for index,layer in enumerate(layers) if type(layer) is MaxPooling2D][-2]\n",
    "print(maxpool_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in layers[:maxpool_idx+1]: layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_ft = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_ft.add(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 43)                6602027   \n",
      "=================================================================\n",
      "Total params: 21,316,715\n",
      "Trainable params: 8,910,635\n",
      "Non-trainable params: 12,406,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_ft.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trn = load_array(results + 'trn_res.dat')\n",
    "X_vld = load_array(results + 'val_res.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 1, 1, 2048) (4410, 1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(X_trn.shape, X_vld.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(43, (3,3), padding='same', input_shape = X_trn.shape[1:]))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/20\n",
      "34799/34799 [==============================] - 2s - loss: 3.4724 - acc: 0.0689 - val_loss: 3.5272 - val_acc: 0.0823\n",
      "Epoch 2/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.4148 - acc: 0.0883 - val_loss: 3.4869 - val_acc: 0.0791\n",
      "Epoch 3/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.3726 - acc: 0.0942 - val_loss: 3.4686 - val_acc: 0.0889\n",
      "Epoch 4/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.3385 - acc: 0.1070 - val_loss: 3.4676 - val_acc: 0.1082\n",
      "Epoch 5/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.3089 - acc: 0.1201 - val_loss: 3.4331 - val_acc: 0.1388\n",
      "Epoch 6/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.2801 - acc: 0.1339 - val_loss: 3.4242 - val_acc: 0.1027\n",
      "Epoch 7/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.2571 - acc: 0.1385 - val_loss: 3.4097 - val_acc: 0.1070\n",
      "Epoch 8/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.2359 - acc: 0.1490 - val_loss: 3.4007 - val_acc: 0.1050\n",
      "Epoch 9/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.2117 - acc: 0.1588 - val_loss: 3.3844 - val_acc: 0.0966\n",
      "Epoch 10/20\n",
      "34799/34799 [==============================] - 0s - loss: 3.1894 - acc: 0.1720 - val_loss: 3.3718 - val_acc: 0.1308\n",
      "Epoch 11/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.1705 - acc: 0.1760 - val_loss: 3.3503 - val_acc: 0.1497\n",
      "Epoch 12/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.1506 - acc: 0.1857 - val_loss: 3.3431 - val_acc: 0.1279\n",
      "Epoch 13/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.1344 - acc: 0.1932 - val_loss: 3.3163 - val_acc: 0.1322\n",
      "Epoch 14/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.1161 - acc: 0.1954 - val_loss: 3.3232 - val_acc: 0.1483\n",
      "Epoch 15/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.0975 - acc: 0.2047 - val_loss: 3.3053 - val_acc: 0.1270\n",
      "Epoch 16/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.0823 - acc: 0.2102 - val_loss: 3.2983 - val_acc: 0.1340\n",
      "Epoch 17/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.0680 - acc: 0.2127 - val_loss: 3.2927 - val_acc: 0.1338\n",
      "Epoch 18/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.0518 - acc: 0.2192 - val_loss: 3.2706 - val_acc: 0.1676\n",
      "Epoch 19/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.0373 - acc: 0.2247 - val_loss: 3.2686 - val_acc: 0.1807\n",
      "Epoch 20/20\n",
      "34799/34799 [==============================] - 1s - loss: 3.0204 - acc: 0.2340 - val_loss: 3.2490 - val_acc: 0.1871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff595322dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x=X_trn, y=Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_vld, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
