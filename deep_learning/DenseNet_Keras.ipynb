{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = \"/media/shreyas/DATA/ML_DATA/traffic_signs/train.p\"\n",
    "valid_data = \"/media/shreyas/DATA/ML_DATA/traffic_signs/valid.p\"\n",
    "test_data = \"/media/shreyas/DATA/ML_DATA/traffic_signs/test.p\"\n",
    "results = \"/media/shreyas/DATA/ML_DATA/traffic_signs/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from keras.backend import tf as k\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from utils import *\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "with open(train_data, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(test_data, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open(valid_data, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (34799, 32, 32, 3)\n",
      "34799 train samples\n",
      "4410 valid samples\n",
      "12630 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'valid samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/MAAAF0CAYAAABv1mnqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51ef1abcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_label_counter = Counter(y_train)\n",
    "\n",
    "train_counter = Counter(y_train)\n",
    "order = list(zip(*train_counter.most_common()))[0]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 4))\n",
    "ax = sns.countplot(x=y_train, order=order, color='lightblue', ax=ax, label=\"train\")\n",
    "\n",
    "_ = ax.set_title('Class distribution')\n",
    "_ = ax.legend(ncol=2, loc=\"upper right\", frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 43)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 43)\n",
    "Y_valid = np_utils.to_categorical(y_valid, 43)\n",
    "Y_test = np_utils.to_categorical(y_test, 43)\n",
    "\n",
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_samples = X_train.shape[0]\n",
    "nb_valid_samples = X_valid.shape[0]\n",
    "batch_size = 32\n",
    "steps_per_epoch = nb_train_samples // batch_size\n",
    "valid_steps = nb_valid_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return Activation('relu')(x)\n",
    "def dropout(x, p): return Dropout(p)(x) if p else x\n",
    "def bn(x): return BatchNormalization()(x)\n",
    "def relu_bn(x): return relu(bn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, nf, sz, wd, p):\n",
    "    x = Conv2D(nf, (sz, sz), kernel_initializer=\"he_uniform\", padding='same', \n",
    "                          kernel_regularizer=regularizers.l2(wd))(x)\n",
    "    return dropout(x,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x, nf, bottleneck=False, p=None, wd=0):\n",
    "    x = relu_bn(x)\n",
    "    if bottleneck: x = relu_bn(conv(x, nf * 4, 1, wd, p))\n",
    "    return conv(x, nf, 3, wd, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(x, nb_layers, growth_rate, bottleneck=False, p=None, wd=0):\n",
    "    if bottleneck: nb_layers //= 2\n",
    "    for i in range(nb_layers):\n",
    "        b = conv_block(x, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        x = merge([x,b], mode='concat', concat_axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_block(x, compression=1.0, p=None, wd=0):\n",
    "    nf = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = relu_bn(x)\n",
    "    x = conv(x, nf, 1, wd, p)\n",
    "    return AveragePooling2D((2, 2), strides=(2, 2))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dense_net(nb_classes, img_input, depth=40, nb_block=3, \n",
    "     growth_rate=12, nb_filter=16, bottleneck=False, compression=1.0, p=None, wd=0, activation='softmax'):\n",
    "    \n",
    "    assert activation == 'softmax' or activation == 'sigmoid'\n",
    "    assert (depth - 4) % nb_block == 0\n",
    "    nb_layers_per_block = int((depth - 4) / nb_block)\n",
    "    nb_layers = [nb_layers_per_block] * nb_block\n",
    "\n",
    "    x = conv(img_input, nb_filter, 3, wd, 0)\n",
    "    for i,block in enumerate(nb_layers):\n",
    "        x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        if i != len(nb_layers)-1:\n",
    "            x = transition_block(x, compression=compression, p=p, wd=wd)\n",
    "\n",
    "    x = relu_bn(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    return Dense(nb_classes, activation=activation, kernel_regularizer=regularizers.l2(wd))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = create_dense_net(43, img_input, depth=100, nb_filter=16, compression=0.5, \n",
    "                     bottleneck=True, p=0.2, wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "      optimizer=keras.optimizers.SGD(0.1, 0.9, nesterov=True), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/20\n",
      "34799/34799 [==============================] - 297s - loss: 2.5972 - acc: 0.4039 - val_loss: 2.5333 - val_acc: 0.4823\n",
      "Epoch 2/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.9611 - acc: 0.8768 - val_loss: 1.0174 - val_acc: 0.8927\n",
      "Epoch 3/20\n",
      "34799/34799 [==============================] - 287s - loss: 0.6329 - acc: 0.9649 - val_loss: 1.6294 - val_acc: 0.7254\n",
      "Epoch 4/20\n",
      "34799/34799 [==============================] - 287s - loss: 0.5195 - acc: 0.9799 - val_loss: 0.7751 - val_acc: 0.9039\n",
      "Epoch 5/20\n",
      "34799/34799 [==============================] - 290s - loss: 0.4465 - acc: 0.9857 - val_loss: 0.7616 - val_acc: 0.9002\n",
      "Epoch 6/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.3875 - acc: 0.9878 - val_loss: 0.5601 - val_acc: 0.9454\n",
      "Epoch 7/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.3282 - acc: 0.9912 - val_loss: 1.8599 - val_acc: 0.7381\n",
      "Epoch 8/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.3024 - acc: 0.9895 - val_loss: 0.5724 - val_acc: 0.9370\n",
      "Epoch 9/20\n",
      "34799/34799 [==============================] - 286s - loss: 0.2659 - acc: 0.9922 - val_loss: 0.5183 - val_acc: 0.9306\n",
      "Epoch 10/20\n",
      "34799/34799 [==============================] - 285s - loss: 0.2398 - acc: 0.9926 - val_loss: 0.4571 - val_acc: 0.9340\n",
      "Epoch 11/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.2154 - acc: 0.9932 - val_loss: 0.5842 - val_acc: 0.9161\n",
      "Epoch 12/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.2065 - acc: 0.9925 - val_loss: 0.5264 - val_acc: 0.9134\n",
      "Epoch 13/20\n",
      "34799/34799 [==============================] - 293s - loss: 0.1923 - acc: 0.9923 - val_loss: 0.9546 - val_acc: 0.8615\n",
      "Epoch 14/20\n",
      "34799/34799 [==============================] - 292s - loss: 0.1848 - acc: 0.9928 - val_loss: 0.3416 - val_acc: 0.9542\n",
      "Epoch 15/20\n",
      "34799/34799 [==============================] - 293s - loss: 0.1721 - acc: 0.9939 - val_loss: 0.4713 - val_acc: 0.9426\n",
      "Epoch 16/20\n",
      "34799/34799 [==============================] - 294s - loss: 0.1577 - acc: 0.9950 - val_loss: 0.5070 - val_acc: 0.9193\n",
      "Epoch 17/20\n",
      "34799/34799 [==============================] - 292s - loss: 0.1578 - acc: 0.9930 - val_loss: 0.7189 - val_acc: 0.8868\n",
      "Epoch 18/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.1462 - acc: 0.9960 - val_loss: 0.3033 - val_acc: 0.9560\n",
      "Epoch 19/20\n",
      "34799/34799 [==============================] - 290s - loss: 0.1495 - acc: 0.9931 - val_loss: 0.4535 - val_acc: 0.9111\n",
      "Epoch 20/20\n",
      "34799/34799 [==============================] - 298s - loss: 0.1464 - acc: 0.9944 - val_loss: 0.2752 - val_acc: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5118b21860>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.1)\n",
    "model.fit(X_train, y_train, 64, 20, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/4\n",
      "34799/34799 [==============================] - 289s - loss: 0.1276 - acc: 0.9989 - val_loss: 0.1618 - val_acc: 0.9884\n",
      "Epoch 2/4\n",
      "34799/34799 [==============================] - 285s - loss: 0.1230 - acc: 0.9995 - val_loss: 0.1585 - val_acc: 0.9878\n",
      "Epoch 3/4\n",
      "34799/34799 [==============================] - 288s - loss: 0.1196 - acc: 0.9997 - val_loss: 0.1505 - val_acc: 0.9891\n",
      "Epoch 4/4\n",
      "34799/34799 [==============================] - 288s - loss: 0.1164 - acc: 0.9999 - val_loss: 0.1472 - val_acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f512f91f9b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.01)\n",
    "model.fit(X_train, y_train, 64, 4, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.1389 - acc: 0.9936 - val_loss: 0.4966 - val_acc: 0.9254\n",
      "Epoch 2/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1400 - acc: 0.9935 - val_loss: 0.4093 - val_acc: 0.9392\n",
      "Epoch 3/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1295 - acc: 0.9961 - val_loss: 0.3114 - val_acc: 0.9492\n",
      "Epoch 4/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1285 - acc: 0.9951 - val_loss: 0.2037 - val_acc: 0.9748\n",
      "Epoch 5/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1321 - acc: 0.9941 - val_loss: 0.5978 - val_acc: 0.9132\n",
      "Epoch 6/20\n",
      "34799/34799 [==============================] - 290s - loss: 0.1392 - acc: 0.9932 - val_loss: 0.2569 - val_acc: 0.9571\n",
      "Epoch 7/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1291 - acc: 0.9963 - val_loss: 0.5426 - val_acc: 0.9091\n",
      "Epoch 8/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.1278 - acc: 0.9956 - val_loss: 0.1867 - val_acc: 0.9810\n",
      "Epoch 9/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.1141 - acc: 0.9969 - val_loss: 0.2192 - val_acc: 0.9664\n",
      "Epoch 10/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1183 - acc: 0.9959 - val_loss: 0.2185 - val_acc: 0.9680\n",
      "Epoch 11/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1325 - acc: 0.9926 - val_loss: 0.2938 - val_acc: 0.9526\n",
      "Epoch 12/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1239 - acc: 0.9955 - val_loss: 0.2358 - val_acc: 0.9694\n",
      "Epoch 13/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1233 - acc: 0.9945 - val_loss: 0.4429 - val_acc: 0.9204\n",
      "Epoch 14/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1174 - acc: 0.9966 - val_loss: 0.1746 - val_acc: 0.9762\n",
      "Epoch 15/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1192 - acc: 0.9949 - val_loss: 0.2650 - val_acc: 0.9553\n",
      "Epoch 16/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1214 - acc: 0.9952 - val_loss: 0.1675 - val_acc: 0.9841\n",
      "Epoch 17/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1028 - acc: 0.9985 - val_loss: 0.2440 - val_acc: 0.9501\n",
      "Epoch 18/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1169 - acc: 0.9948 - val_loss: 0.1447 - val_acc: 0.9864\n",
      "Epoch 19/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1183 - acc: 0.9947 - val_loss: 0.6680 - val_acc: 0.8889\n",
      "Epoch 20/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1182 - acc: 0.9953 - val_loss: 0.2923 - val_acc: 0.9515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5117a85c50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.1)\n",
    "model.fit(X_train, y_train, 64, 20, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.1055 - acc: 0.9986 - val_loss: 0.1257 - val_acc: 0.9934\n",
      "Epoch 2/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0995 - acc: 0.9996 - val_loss: 0.1282 - val_acc: 0.9923\n",
      "Epoch 3/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0971 - acc: 0.9998 - val_loss: 0.1201 - val_acc: 0.9948\n",
      "Epoch 4/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0946 - acc: 0.9998 - val_loss: 0.1161 - val_acc: 0.9966\n",
      "Epoch 5/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0922 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9959\n",
      "Epoch 6/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0904 - acc: 1.0000 - val_loss: 0.1136 - val_acc: 0.9941\n",
      "Epoch 7/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0886 - acc: 0.9999 - val_loss: 0.1141 - val_acc: 0.9937\n",
      "Epoch 8/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0865 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9964\n",
      "Epoch 9/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0848 - acc: 0.9999 - val_loss: 0.1084 - val_acc: 0.9955\n",
      "Epoch 10/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0830 - acc: 0.9999 - val_loss: 0.1058 - val_acc: 0.9946\n",
      "Epoch 11/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0812 - acc: 0.9999 - val_loss: 0.1017 - val_acc: 0.9964\n",
      "Epoch 12/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0796 - acc: 0.9999 - val_loss: 0.1007 - val_acc: 0.9955\n",
      "Epoch 13/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0777 - acc: 0.9999 - val_loss: 0.0997 - val_acc: 0.9964\n",
      "Epoch 14/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0761 - acc: 0.9999 - val_loss: 0.0976 - val_acc: 0.9961\n",
      "Epoch 15/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0745 - acc: 1.0000 - val_loss: 0.0969 - val_acc: 0.9959\n",
      "Epoch 16/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0730 - acc: 0.9999 - val_loss: 0.0948 - val_acc: 0.9964\n",
      "Epoch 17/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0715 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9964\n",
      "Epoch 18/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0701 - acc: 0.9999 - val_loss: 0.0925 - val_acc: 0.9957\n",
      "Epoch 19/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0688 - acc: 0.9999 - val_loss: 0.0883 - val_acc: 0.9959\n",
      "Epoch 20/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0671 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5117a85c88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.01)\n",
    "model.fit(X_train, y_train, 64, 20, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/20\n",
      "34799/34799 [==============================] - 287s - loss: 0.0664 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9961\n",
      "Epoch 2/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0661 - acc: 1.0000 - val_loss: 0.0871 - val_acc: 0.9961\n",
      "Epoch 3/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0660 - acc: 0.9999 - val_loss: 0.0866 - val_acc: 0.9961\n",
      "Epoch 4/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0659 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 0.9961\n",
      "Epoch 5/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0657 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9964\n",
      "Epoch 6/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0656 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9964\n",
      "Epoch 7/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0655 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9964\n",
      "Epoch 8/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0652 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9961\n",
      "Epoch 9/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0652 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9964\n",
      "Epoch 10/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0650 - acc: 0.9999 - val_loss: 0.0856 - val_acc: 0.9964\n",
      "Epoch 11/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0648 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9964\n",
      "Epoch 12/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0647 - acc: 0.9999 - val_loss: 0.0848 - val_acc: 0.9964\n",
      "Epoch 13/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0646 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9964\n",
      "Epoch 14/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0645 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 0.9964\n",
      "Epoch 15/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0643 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9964\n",
      "Epoch 16/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0642 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 0.9964\n",
      "Epoch 17/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0641 - acc: 1.0000 - val_loss: 0.0838 - val_acc: 0.9964\n",
      "Epoch 18/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0641 - acc: 0.9999 - val_loss: 0.0833 - val_acc: 0.9964\n",
      "Epoch 19/20\n",
      "34799/34799 [==============================] - 288s - loss: 0.0638 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9964\n",
      "Epoch 20/20\n",
      "34799/34799 [==============================] - 289s - loss: 0.0637 - acc: 0.9999 - val_loss: 0.0832 - val_acc: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5117a85d68>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.001)\n",
    "model.fit(X_train, y_train, 64, 20, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
